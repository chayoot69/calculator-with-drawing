import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, utils
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array
import os

# --- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Path ‡∏Ç‡∏≠‡∏á Dataset ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢ ---
DATASET_PATH = 'dataset' # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Kaggle ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì

# --- 1. ‡πÇ‡∏´‡∏•‡∏î MNIST (‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç 0-9) ---
print("1. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î MNIST (‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)...")
(x_digits, y_digits), _ = tf.keras.datasets.mnist.load_data()

# ‡∏õ‡∏£‡∏±‡∏ö Shape ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô (N, 28, 28, 1) ‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏™‡∏µ 0-1
x_digits = x_digits.reshape(-1, 28, 28, 1).astype('float32') / 255.0
# y_digits ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏õ‡πá‡∏ô 0-9 ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß

print(f"   -> ‡πÑ‡∏î‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏°‡∏≤ {len(x_digits)} ‡∏£‡∏π‡∏õ")

# --- 2. ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏à‡∏≤‡∏Å Kaggle (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ + - * /) ---
print("2. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏à‡∏≤‡∏Å Kaggle...")

# ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢ (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏•‡∏Ç 0-9 ‡∏Ç‡∏≠‡∏á Kaggle)
symbol_map = {
    'add': 10, 
    'sub': 11, 
    'mul': 12, 
    'div': 13
}

x_symbols = []
y_symbols = []

for folder_name, label_id in symbol_map.items():
    folder_path = os.path.join(DATASET_PATH, folder_name)
    if not os.path.exists(folder_path):
        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {folder_name}")
        continue
        
    for f in os.listdir(folder_path):
        try:
            path = os.path.join(folder_path, f)
            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
            if img is None: continue
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏õ‡πá‡∏ô 28x28 ‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤ MNIST
            img = cv2.resize(img, (28, 28))
            
            # ‡∏Å‡∏•‡∏±‡∏ö‡∏™‡∏µ (‡∏ñ‡πâ‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏Ç‡∏≤‡∏ß ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏î‡∏≥)
            if np.mean(img) > 127: img = cv2.bitwise_not(img)
            
            x_symbols.append(img_to_array(img))
            y_symbols.append(label_id)
        except: pass

x_symbols = np.array(x_symbols).astype('float32') / 255.0
y_symbols = np.array(y_symbols)

print(f"   -> ‡πÑ‡∏î‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏°‡∏≤ {len(x_symbols)} ‡∏£‡∏π‡∏õ (‡∏¢‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏≠‡∏¢‡∏π‡πà)")

# --- 3. ‡∏õ‡∏±‡πä‡∏°‡∏¢‡∏≠‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢ (Balancing) ---
# MNIST ‡∏°‡∏µ 60,000 ‡∏£‡∏π‡∏õ ‡πÅ‡∏ï‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏°‡∏µ‡πÅ‡∏Ñ‡πà 2,000
# ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡πä‡∏≠‡∏õ‡∏õ‡∏µ‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ã‡πâ‡∏≥‡πÜ ‡πÉ‡∏´‡πâ‡πÄ‡∏¢‡∏≠‡∏∞‡∏Ç‡∏∂‡πâ‡∏ô (AI ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏•‡∏≥‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏ï‡∏≠‡∏ö‡πÅ‡∏ï‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)
print("3. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏±‡πä‡∏°‡∏¢‡∏≠‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡∏™‡∏π‡∏™‡∏µ‡∏Å‡∏±‡∏ô...")

# ‡∏Å‡πä‡∏≠‡∏õ‡∏õ‡∏µ‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ã‡πâ‡∏≥ 15 ‡∏£‡∏≠‡∏ö (2,000 x 15 = 30,000 ‡∏£‡∏π‡∏õ)
x_symbols = np.tile(x_symbols, (15, 1, 1, 1))
y_symbols = np.tile(y_symbols, (15,))

print(f"   -> ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢ {len(x_symbols)} ‡∏£‡∏π‡∏õ‡πÅ‡∏•‡πâ‡∏ß!")

# --- 4. ‡∏£‡∏ß‡∏°‡∏£‡πà‡∏≤‡∏á (Hybrid Dataset) ---
x_train = np.concatenate((x_digits, x_symbols), axis=0)
y_train = np.concatenate((y_digits, y_symbols), axis=0)

# ‡∏™‡∏•‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ß (Shuffle)
idx = np.arange(len(x_train))
np.random.shuffle(idx)
x_train, y_train = x_train[idx], y_train[idx]

y_train = utils.to_categorical(y_train, 14)

# --- 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ---
model = models.Sequential([
    layers.Input(shape=(28, 28, 1)),
    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(14, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏π‡∏Å‡∏ú‡∏™‡∏° (Hybrid)...")
# ‡πÉ‡∏ä‡πâ Data Augmentation ‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏¥‡∏î‡∏£‡∏π‡∏õ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏Å‡πä‡∏≠‡∏õ‡∏°‡∏≤ ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô
datagen = ImageDataGenerator(
    rotation_range=15, 
    width_shift_range=0.1, 
    height_shift_range=0.1, 
    zoom_range=0.1
)

model.fit(datagen.flow(x_train, y_train, batch_size=64), epochs=15, verbose=1)

model.save('math_model_hybrid.h5')
print("üéâ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡πÑ‡∏î‡πâ‡πÑ‡∏ü‡∏•‡πå 'math_model_hybrid.h5' ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß!")